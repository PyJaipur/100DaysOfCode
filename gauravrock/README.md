# Gaurav Sharma
 * Final Year CSE(Inquisitive , energetic computer science specialist skills and leadership with a strong Foundation in math programming logic and cross platform coding. Seeking to leverage solid development skills with a focus on collaboration ,communication ,passion and creativity as a programmer.)
 * intern at Axis india machine learning
 * Plans for 100DaysOfCode:shipit:
 
# Improving Algorithmic thinking.
  Solving some Kaggle Problems.
 - [ ] Improving Python Skills with #project euler and #leetcode.
 - [ ] publish 2 research papers on decision tree and KNN.
 - [ ] reading 10 books (Technical/Non-Technical)
 - [ ] follow up 3 months path by @sirajraval for Data science in 100 days.
 - [ ] Read the Book - Learn python the hard way 3
  
  
## Day - -1 : Jan 1st 2019
- Prepared My Introduction Here and Planning here.
- Started working with datacamp path to data science and machine learning & started solving chllenges.:+1:
## Day - -2 : Jan 2nd 2019
- completed the datacamp introduction to python for data science.(it was a great introduction in a very subtle and efficient way to get a glimpse of library like NUMPY and compare it with lists in python) [here certificate](https://www.datacamp.com/statement-of-accomplishment/course/9e38d8d76524521571c801d81ce11a19707a896c)
- worked with linear regression algorithms and started to implement using jupyter notebook.
- learned the basic of web scraping using python.
## Day - -3 : Jan 3rd 2019
- worked with web crawler and scraping using python and packages like Http requests and BeautifulSoup to crawl the links and images and tried to make a youtube downloader(but failed suddenly due to strong regex of youtube but will try again!:sweat_smile:).
- also had a hands on some packages of python for ML and datascience such as Matplotlib , pandas etc from datacamp.
## Day - -4 : Jan 4th 2019
- worked with Matplotlib and pandas .These python packages are great when it comes to data visualization and Data munging in python).
## Day - -5: Jan 5th 2019
- Read the book Learn python3 the hard way by ZED A. SHAW(a wonderful book to learn the core of python with every great detail)
## Day - -6 : Jan 6th 2019
- completed the datacamp's intermediate to python for data science.(it was a great introduction in a very subtle and efficient way to get a glimpse of library like matplotlib and using hacker statistics to solve some data science problem) [here certificate](https://www.datacamp.com/statement-of-accomplishment/course/84d76fa4bda94d6669c16b1e19a36539e1e56046)
## Day - -7 : Jan 7th 2019
-worked with python automation and establish it using Jupyter notebook.
## Day - -8 : Jan 8th 2019
#day8 It's almost 1 week in #100DaysOfCode  or #100DaysOfMLCode. Today, worked with understanding the basic Neural net & backpropagation techniques to derive more accuracy.
## Day - -9 : Jan 9th 2019
- #day9 was worth in learning the basic of functions and Understanding the LEGB functions rules and also, working with foliumüó∫Ô∏è package for maps---this package if great to demonstrate the data over the world map.
## Day - -10 : Jan 10th 2019
-completed the Python Data Science Toolbox (Part 1) and explored the core of functions in python including the lambda and various methods in functions like map and filter. Ultimately the goal was to work with the Dataset.
[here certificate](https://www.datacamp.com/statement-of-accomplishment/course/24f17e2fadc17109b6fce16a10ddcd106ac6fcd6)
## Day - -11 : Jan 11th 2019
- #day11 Worked with open lane detectionüõ£Ô∏è using OpenCV, This is one of the computer vision problems to tackle in Self-driving carsüöó in the 21st century i.e., to develop more precise algorithms for detection.ü§ñüßê
## Day - -12 : Jan 12th 2019
- worked with coding problem on hackearth and other hackerrank
## Day - -13 : Jan 13th 2019
- worked with competitve programming on various portals and started working with pyjudge project.
## Day - -14 : Jan 14th 2019
- learn the basic of git and how to embed that to the project.
## Day - -15 : Jan 15th 2019
- learn the core basics of probability and statistics. Understanding the Frequent ist and Bayesian statistics is funüìèüìé and also understood the difference b/w relative frequency and probability when applied to sample and population of data. 
## Day - -16 : Jan 16th 2019
- #day16 understand the core concept of Descriptive statement and probability distribution. And, a difference between the continuous and discrete random variables. Probabilistic distribution has the power that can derive the formula for randomness
## Day - -17 : Jan 17th 2019
- #day17 worked with PMF functions using scipy library ad plotted the probability function. And learned to generate fake-data using descriptive statistics. 
## Day - -18 : Jan 18th 2019
- Learned the Gaussian distribution and why normal distribution is called the Gaussian distribution.
## Day - -19 : Jan 19th 2019
- Learned the basics of cumulative probability and how to calculate the Gaussian value using the Normal curve table. And, also understand the basics difference between standard normal distribution and normal distribution.
## Day - -20 : Jan 20th 2019
- worked with the Binominal & Normal distribution. Also, get an instance of how the these are mapping the world and how Z-score is used in Standard Normal probablity Distribution.

## Day - -21 : Jan 21th 2019
- worked with the Inferencial statistics and understand how vast effect inferencial from probability distribution has on the real world. This map the basics of Machine learning and data analysis.
## Day - -22 : Jan 22th 2019
- Generated the fake data using descriptive statistics and plotted that using Matplotlib and scipy. Also, worked with Dice-throw problem using Binomial distribution.
## Day - -23 : Jan 23th 2019
- Worked with MAXIMUM LIKELIHOOD ESTIMATION algorithm for finding the MUV estimator for the natural parameter of probability distribution. This is at the core of Inferential statistics.
## Day - -24 : Jan 24th 2019
- #Day24 Set up a project in a git and this is going to be the second open source contribution in a row.(more details-- s√≥√≥√±ü§ñ) Also worked with the inferential stats at its core.ü§ì 
## Day - -25 : Jan 25th 2019
- Learned the second and most important application of Inferential stats i.e., to determine whether the treatment of something has asignificant effect on population or not?? This has a great useful in data analysis as well as business analyst.
## Day - -26 : Jan 26th 2019
- worked with list & dictionary comprehension as well as generators to stream a large bunch of data. Gained datacamp [certificate] (https://www.datacamp.com/statement-of-accomplishment/course/ccaf7ebb7b1406a63ea5dfe28b724365fb7ca347)
## Day - -27 : Jan 27th 2019
- worked with Type1 and Type2 category error. These two erroes defines the category of error in machine learning and various deep learning problems. 
## Day - -28 : Jan 28th 2019
- worked with pyjudge project(bottle framework). Revised the probaility and statistics. Moreover, my research paper on decision tree got selected ICPCCAI-19 for ORAL presentation. 
## Day - -29 : Jan 29th 2019
- Learn the possion and rayleigh distribution function and what are their applications in real world scenerio. 
## Day - -30 : Jan 30th 2019
- learned the concept of X% confidence interval. This totally defines second application of inferential stats.
## Day - -31 : Jan 31th 2019
- worked with p-value in inferential statistics. Also, learned the data structure and algorithms(searching & sorting).
## Day - -32 : feb 1st 2019
- Plotted the confidence interval in jupyter notebook. learned the data structure and algorithm.
## Day - -33 : feb 2nd 2019
- Worked with Monte-carlo approach in inferential stats and clearly understand the significance value and tail area.(This is the beginning of ML).
## Day - -34 : feb 3nd 2019
- learn some tutorials from udacity for natural language processing & also worked with flask framework in pythonüå∂.*
## Day - -35 : feb 4th 2019
- Learned the difference b/w small and large samples. And, why t-value is used in small sample. just Going through each nutüî© and bolt‚öôÔ∏è of stats and probability distribution.
## Day - -36 : feb 5th 2019
- read the [research paper](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/b8c26e4347adc3453c15d96a09e6f7f102293f71.pdf) in nlp NQ-by google. This technology is gonna change the furture how the NLP operates.
## Day - -37 : feb 6th 2019
- worked with Annova(analysis of variance) in probability distribution & what is the intuition behind it. 
## Day - -38 : feb 7th 2019
- worked with dataset to infer the paired hypothesis.
## Day - -39 : feb 8th 2019
- Read the book on probability and statistics by beaver & beaver.
## Day - -40 : feb 9th 2019 
- worked on dataset with scikit-learn.
## Day - -41 : feb 10th 2019
- learned the concepts of frequentist inferential statistics.
## Day - -42 : feb 11th 2019
- worked with f-distribution in inferential stats.
## Day - -43 : feb 12th 2019
- learned the concepts of ANNOVA: small sample hypothesis testing for variance of multiple populations.(It helps in originating the various concepts of PCA in Ml)‚ùï
## Day - -44 : feb 13th 2019
- learned the scheffe's hypothesis test for 1 factor ANNOVA.
## Day - -45 : feb 14th 2019
- learned the 2nd most important hypothesis test for ANNOVA i.e., Tukey test. Also, got familiar with Covariance concept.
## Day - -46 : feb 15th 2019
- learned the concept of pearson Corelation Coefficient hypothesis test.üé≠
## Day - -47 : feb 16th 2019
- learned the concepts of chi-square in statistics.
## Day - -48 : feb 17th 2019
- code chef and hackerrank.(10 days of probability and stats)
## Day - -49 : feb 18th 2019
- read the research paper on qc corpus NLP.
## Day - -50 : feb 19th 2019
- written 2 pages of my next research paper.
## Day - -51 : feb 20th 2019
- learned some concepts of Non-parametric statistics(Bayesian stats).
## Day - -52 : feb 21th 2019
- learned the wilcoxon rank sum test.
## Day - -53 : feb 22th 2019
- learned the concept of wilcoxon signed test.
## Day - -54 : feb 23rd 2019
- started some project on naive-bayes classifier.(understanding the root of classification: one of the five key elements of AI)
## Day - -55 : feb 24th 2019
- Trained a model on tumor Dataset on the basis of size.
(i have added the books for anyone reading to understand the core of stats in read_books folderüëÄ)
## Day - -56 : feb 25th 2019
- started working with linear algebra for deep learning.
## Day - -57 : feb 26th 2019
- learned the concept of covariance matrix in vectors.
## Day - -58 : feb 27th 2019
- trained the model of naive bayes for multiple column dataset and achieved 85% accuracy.
## Day - -59 : feb 28th 2019
- training naive bayes without scikit-learn from scratch.
 [data-set](https://www.kaggle.com/uciml/breast-cancer-wisconsin-data)
## Day - -60 : march 1st 2019
- learn more about singular matrix and how to use co-variance matrix in naive bayes algo.
## Day - -61 : march 2nd 2019
- selected some organisations for GSOC-19.
## Day - -62 : march 3rd 2019
- learn the gaussian elimination for a matrix.
## day - -63 : march 4th 2019
- Elimination matrix in vectors.(learn from Gilbert strang a.k.a the father of vectors.)
## day - -64 : march 5th 2019
- learn the latex.(to write mathematical expressions in python)
## day - -65 : march 6th 2019
- watch the tensorflow dev summit and also worked with vectors(linear algebra).
## day - -66 : march 7th 2019
- worked out the multivariate gaussian naive bayes from scratch without any libarary.(working from scratch helps in knowing what is hiden behind librariesü§™) -soon will add the code.
## day - -67 : march 8th 2019
- learned the concept of positive definite, positive semidefinite & negative definite.
## day - -68 : march 9th 2019
- Trying to get the maximum accuracy in naive bayes using another great concept of Qda ,Lda and Rda. The last concept got singular matrix at the end which resulted in the decreasing the accuracy and precision also some conflicts with pooled co-variance matrix.ü§Ø
## day - -69 : march 10th 2019
- learned the concept of vector spaces in linear algebra.
## day - -70 : march 11th 2019
- learned the sympy and unit testing(also some continous integration).
## day - -71 : march 12th 2019
- Trying to implement the same naive bayes classifier for [Devanagari Handwritten Character Dataset Data Set ](https://www.kaggle.com/uciml/breast-cancer-wisconsin-data). This time it's an application for computer vision.üíª
## day - -72 : march 13th 2019
- worked with hackerrank [10 days of statistics](https://www.hackerrank.com/domains/tutorials/10-days-of-statistics?filters%5Bstatus%5D%5B%5D=unsolved&badge_type=10-days-of-statistics) and solved 20 problems.
## day - -73 : march 14th 2019
- learned the concept of rank in linear algebra.
## day - -74 : march 15th 2019
- Played with some pixels on naive bayes on Devnagri dataset and tried to classify things.
## day - -75 : march 16th 2019
- Tried coding all the problems and concepts in prob. and stats as per Think stats book from O'reiley.
## day - -76 : march 17th 2019
- Tried hands on oop programming concepts from python 3 Handbook.
## day - -77 : march 18th 2019
- learn some advance concepts from treehouse.
## day - -78 : march 19th 2019
- worked with some testing using python.
## day - -79 : march 20th 2019
- Opted for some probability and statistics from edx using python.
## day - -80 : march 21th 2019
- Was a bit procrastinate in uploading to github due to festival seasons in India. But somehow managed to learn some gaming concepts treehouse.
## day - -81 : march 22th 2019
- Get in flow with the linear algebra. 
## day - -82 : march 23th 2019
- Tried revising the previous concepts to get at the core of mathematics.(it is rootüå¥ of ML)
## day - -83 : march 24th 2019
- learned the concept of boxplot.
## day - -84 : march 25th 2019
- learned Lda and what is determinant function? and how it helps in dealing with singular matrix(covarinace matrix).
## day - -85 : march 26th 2019
- learned the concept of projection in vector and plane.
## day - -86 : march 27th 2019
- learned the concept of of RREF in projection of vectors.
## day - -87 : march 28th 2019
- learned the concept of eigen vectors and how important they are in covarinace matrix.